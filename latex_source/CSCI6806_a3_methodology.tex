%%
%% This is file `sample-sigconf.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx  (with options: `all,proceedings,bibtex,sigconf')
%% 
%% IMPORTANT NOTICE:
%% 
%% For the copyright see the source file.
%% 
%% Any modified versions of this file must be renamed
%% with new filenames distinct from sample-sigconf.tex.
%% 
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%% 
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%%
%% Commands for TeXCount
%TC:macro \cite [option:text,text]
%TC:macro \citep [option:text,text]
%TC:macro \citet [option:text,text]
%TC:envir table 0 1
%TC:envir table* 0 1
%TC:envir tabular [ignore] word
%TC:envir displaymath 0 word
%TC:envir math 0 word
%TC:envir comment 0 0
%%
%% The first command in your LaTeX source must be the \documentclass
%% command.
%%
%% For submission and review of your manuscript please change the
%% command to \documentclass[manuscript, screen, review]{acmart}.
%%
%% When submitting camera ready or to TAPS, please change the command
%% to \documentclass[sigconf]{acmart} or whichever template is required
%% for your publication.
%%
%%
\documentclass[sigconf]{acmart}
%%
%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    Bib\TeX}}}

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.
% \setcopyright{acmlicensed}
\setcopyright{none}
% \copyrightyear{2018}
% \acmYear{2018}
% \acmDOI{XXXXXXX.XXXXXXX}
%% These commands are for a PROCEEDINGS abstract or paper.
% \acmConference[Conference acronym 'XX]{Make sure to enter the correct
%   conference title from your rights confirmation email}{June 03--05,
%   2018}{Woodstock, NY}
%%
%%  Uncomment \acmBooktitle if the title of the proceedings is different
%%  from ``Proceedings of ...''!
%%
%%\acmBooktitle{Woodstock '18: ACM Symposium on Neural Gaze Detection,
%%  June 03--05, 2018, Woodstock, NY}
% \acmISBN{978-1-4503-XXXX-X/2018/06}
\acmConference{CSCI6806 Capstone Proj}{Sep. 2025}{Vancouver, BC, CA}

\settopmatter{printacmref=false} % removes the footnote below the first column
\renewcommand\footnotetextcopyrightpermission[1]{} % removes conference info footnote

%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

%%
%% For managing citations, it is recommended to use bibliography
%% files in BibTeX format.
%%
%% You can then either use BibTeX with the ACM-Reference-Format style,
%% or BibLaTeX with the acmnumeric or acmauthoryear sytles, that include
%% support for advanced citation of software artefact from the
%% biblatex-software package, also separately available on CTAN.
%%
%% Look at the sample-*-biblatex.tex files for templates showcasing
%% the biblatex styles.
%%

%%
%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%%
%% If you are preparing content for an event
%% sponsored by ACM SIGGRAPH, you must use the "author year" style of
%% citations and references.
%% Uncommenting
%% the next command will enable that style.
%%\citestyle{acmauthoryear}

% fix figure
\usepackage{float}
\usepackage{makecell}

\usepackage[inkscapelatex=false]{svg}
\svgsetup{inkscapelatex=false}


%%
%% end of the preamble, start of the body of the document source.
\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title{Group 1: Methodology}

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.

\vfill
\author{Anna Gorislavets}
\affiliation{%
  \institution{Fairleigh Dickinson University}
  \city{Vancouver}
  \country{Canada}
}
\email{a.gorislavets@student.fdu.edu}

\author{Bikash Shyangtang}
\affiliation{%
  \institution{Fairleigh Dickinson University}
  \city{Vancouver}
  \country{Canada}
}
\email{b.shyangtang@student.fdu.edu}

\author{Hao Chen}
\affiliation{%
  \institution{Fairleigh Dickinson University}
  \city{Vancouver}
  \country{Canada}
}
\email{h.chen4@student.fdu.edu}

\author{Maoting Li}
\affiliation{%
  \institution{Fairleigh Dickinson University}
  \city{Vancouver}
  \country{Canada}
}
\email{m.li3@student.fdu.edu}

\author{Salinrat Thanathapsakun}
\affiliation{%
  \institution{Fairleigh Dickinson University}
  \city{Vancouver}
  \country{Canada}
}
\email{s.thanathapsakun@student.fdu.edu}
\vfill


%%
%% By default, the full list of authors will be used in the page
%% headers. Often, this list is too long, and will overlap
%% other information printed in the page headers. This command allows
%% the author to define a more concise list
%% of authors' names for this purpose.
% \renewcommand{\shortauthors}{Trovato et al.}

%%
%% The abstract is a short summary of the work to be presented in the
%% article.
% \begin{abstract}
%   A clear and well-documented \LaTeX\ document is presented as an
%   article formatted for publication by ACM in a conference proceedings
%   or journal publication. Based on the ``acmart'' document class, this
%   article presents and explains many of the common variations, as well
%   as many of the formatting elements an author may use in the
%   preparation of the documentation of their work.
% \end{abstract}

%%
%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
%% Please copy and paste the code instead of the example below.
%%
% \begin{CCSXML}
% <ccs2012>
%  <concept>
%   <concept_id>00000000.0000000.0000000</concept_id>
%   <concept_desc>Do Not Use This Code, Generate the Correct Terms for Your Paper</concept_desc>
%   <concept_significance>500</concept_significance>
%  </concept>
%  <concept>
%   <concept_id>00000000.00000000.00000000</concept_id>
%   <concept_desc>Do Not Use This Code, Generate the Correct Terms for Your Paper</concept_desc>
%   <concept_significance>300</concept_significance>
%  </concept>
%  <concept>
%   <concept_id>00000000.00000000.00000000</concept_id>
%   <concept_desc>Do Not Use This Code, Generate the Correct Terms for Your Paper</concept_desc>
%   <concept_significance>100</concept_significance>
%  </concept>
%  <concept>
%   <concept_id>00000000.00000000.00000000</concept_id>
%   <concept_desc>Do Not Use This Code, Generate the Correct Terms for Your Paper</concept_desc>
%   <concept_significance>100</concept_significance>
%  </concept>
% </ccs2012>
% \end{CCSXML}

% \ccsdesc[500]{Do Not Use This Code~Generate the Correct Terms for Your Paper}
% \ccsdesc[300]{Do Not Use This Code~Generate the Correct Terms for Your Paper}
% \ccsdesc{Do Not Use This Code~Generate the Correct Terms for Your Paper}
% \ccsdesc[100]{Do Not Use This Code~Generate the Correct Terms for Your Paper}

%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
% \keywords{Flash Cache, HDD throughput bottleneck, Disk-head Time (DT)}
%% A "teaser" image appears between the author and affiliation
%% information and the body of the document, and typically spans the
%% page.
% \begin{teaserfigure}
%   \includegraphics[width=\textwidth]{sampleteaser}
%   \caption{Seattle Mariners at Spring Training, 2010.}
%   \Description{Enjoying the baseball game from the third-base
%   seats. Ichiro Suzuki preparing to bat.}
%   \label{fig:teaser}
% \end{teaserfigure}

% \received{20 February 2007}
% \received[revised]{12 March 2009}
% \received[accepted]{5 June 2009}

%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle

% \onecolumn make the document one column
\clearpage
\section{Methodology}

\subsection{Artifact \& Environment Plan}

Following the official Baleen-FAST24 GitHub README for test environment setup, trace data will be downloaded, specifically focusing on "Getting Started" instructions. The main purpose of the artifact repository is to reproduce the simulator results from the Baleen paper published at USENIX FAST 2024 \cite{wong2024baleen}. The repository contains Python code to reproduce the simulator results, with the main instructions located in the README.md, which provides guidance for installation via Conda/pip, trace data download procedures, and step-by-step reproduction commands. The artifact includes preconfigured experiments in the runs/ directory, trace data download script in the data/ directory, analysis notebooks in the notebooks/ directory, and machine learning (ML) models in the tmp/ directory, with the cache simulator code residing in the BCacheSim/ directory (submodule). The Table~\ref{tb:repo_analysis_table_1} shows the repository components.

\begin{table}[H]
\centering
\caption{Examination of Baleen-FAST24 repository}
\label{tb:repo_analysis_table_1}
\small
\begin{tabular}[t]{lp{5.8cm}}
\toprule
\textbf{Repository} & https://github.com/wonglkd/Baleen-FAST24 \\
\midrule
\textbf{Commit ID} & 4e3a920 \\
\midrule
\textbf{Notebooks} & \makecell[l]{notebooks/example/example.ipynb \\ notebooks/reproduce/commands.ipynb \\ notebooks/paper-figs/*.ipynb}\\
\midrule
\textbf{Directory} & \makecell[l]{BCacheSim/ (simulator submodule) \\ data/tectonic/201910/Region1/*.trace (traces) \\ tmp/example/* (ML model) \\ runs/example/* (simulation results)} \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[H]
\centering
\caption{Configuration/Matrics for DT-SLRU}
\label{tb:analysis_table_1}
\small
\begin{tabular}[t]{lp{5.8cm}}
\toprule
\textbf{Admission Policy} & Admit-All \\
\midrule
\textbf{Prefetch} & Disabled \\
\midrule
\textbf{Cache size} & 366.475 GB\\
\midrule
\textbf{Trace slices} & data/tectonic/201910/Region1/full\_0\_0.1.trace \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Repository Scope \& Terminology}

The scope of the artifact encompasses the Python simulator code and notebooks for paper-style reproduction of Baleen's ML admission and prefetching policies, while explicitly excluding the unreleased testbed components that modified proprietary CacheLib internals \cite{wong2024baleen}. The terminology mapping reveals that Service Time in the code corresponds to DT in the paper, representing the time spent accessing backend storage, while Chunks in the code are referred to as Segments in the paper, defining the granularity of data management units. Episodes serve as temporal segments used for ML training and analysis, representing coherent periods of cache behavior, with Optimal Admission Policy (OPT) functioning as the baseline for comparison, and DT representing the dependencies between service time measurements and decision thresholds. The key components include BCacheSim as the Python cache simulator specialized for flash caching in bulk storage systems, EpisodicAnalysis as the ML training framework for admission and prefetching models based on episodes, admission policies comprising Baleen (ML-based), RejectX (baseline), and CoinFlip (baseline), eviction policies including LRU and FIFO, and prefetching capabilities with ML-based prefetching featuring configurable ranges such as episode and access-time-episode-predict.


%salin
\subsection{Planned Policies \& Training}

The comparison will be between a heuristic baseline and Baleen that leverages ML-guided admission (trained via OPT imitation using episodes) in conjunction with coordinated ML prefetching. Models will be trained using the provided examples and scripts in the Baleen-FAST24 artifact.

\subsubsection{Baseline Admission Heuristic}
The baseline admission policy is the RejectX admission policy (such as in the artifact). The eviction configuration and other settings are consistent with what’s given in the example configuration files \cite{wong2024baleen}.

\subsubsection{Baleen: ML-Informed Admission \& Coordinated ML Prefetching}
Baleen separates workload traces into episodes and uses supervised learning to imitate OPT signals for admission while training the prefetch model \cite{wong2024baleen}. This takes advantage of the episodic nature of the workload behavior and helps the system to capture temporal behavior as well as exploit the use of OPT for a supervision signal for better learning. To give the model full information on access patterns, block-level features, and sub-object structure, a combined set of meta, block, and chunk properties will be used. After training, the learned admission and prefetch policies are deployed to characterize cache operations in terms of the workload traces to achieve well-coordinated, adaptive, and efficient cache management.


\subsubsection{Planned Feature Subsets, Workloads \& Starting Hyperparameters} 
The artifact uses a single feature set that combines meta, block, and chunk attributes \cite{wong2024baleen}. The meta features contain access information, the block features correspond to I/O size, offset, and locality, and the chunk features model patterns within sub-objects.
Training \& Evaluation Workloads are extracted from the Baleen24 dataset in Meta’s Tectonic storage stack. The first day (0-86400s) for training and the second day (86400–172800s) for testing purposes. The configuration provides a trade-off for training scope and evaluation fidelity in terms of the trace group selection, downsampling factor, and time window.
The hyper-parameters consist of write-rate targets to test robustness, a cache size target reflecting realistic limits, an eviction age as a temporal threshold when blocks are to be removed, and an admission-prefetch accuracy cutoff ensuring a degree of quality.
The utility policy considers the service time and block size, while the experiment region determines the evaluation range. These arrangements and features allow the model to faithfully approximate OPT signals.



%\begin{flushright}
%\textit{Word count: 282}
%\end{flushright}

\subsection{Planned Workloads \& Temporal Splits}

Pipeline validation will begin with the “Getting Started” subset from the Baleen artifact \cite{wong2024baleen}, which provides lightweight traces and notebooks to evaluate environment setup. After this, the evaluation will extend to additional subsets referenced in the repository.

Temporal splits will be introduced by training on an early portion of each trace and evaluating on later portions, following the methodology in the Baleen paper \cite{wong2024baleen}. This approach prevents leakage and ensures that the evaluation reflects deployment conditions where future access patterns are unknown.

To make DT and Peak DT meaningful, both seek-dominated and bandwidth-dominated regimes will be included. Seek-dominated workloads capture frequent small I/Os, while bandwidth-dominated workloads reflect large sequential transfers. Considering both ensures that the evaluation covers distinct backend stress conditions relevant to cache policy design.

\subsection{Metric Definitions}
A clear set of metrics needs to be defined to evaluate the Baleen article against other heuristic approaches.
 
\subsubsection{Disk-head Time (DT) and Peak DT}
DT is the most straightforward metric to measure the back-end load and refers to the total amount of time the HDD disk heads are active; this metric combines the search time and the time to read an additional byte \cite{wong2024baleen}. Peak DT can be conceptualized as the maximum DT observed in a given timeframe and is more critical than average DT because it reflects the maximum throughput that data storage facilities need \cite{wong2024baleen}. These two metrics will be measured against HDD capacity.

\subsubsection{Flash Write Rate}
Since an SSD has an endurance limit, it imposes restrictions on the usage of flash cache\cite{wong2024baleen,mcallister2021kangaroo}.The total flash write rates will be measured under each admission policy against the rejection threshold. The purpose is to understand how limited flash write rates can be used efficiently to reduce back-end load.

\subsubsection{Estimated TCO}
The TCO will be calculated as the sum of the cost of HDD capacity (driven by Peak DT) and SSD wearout (as a result of flash write rate) \cite{wong2024baleen}. Further, the TCO will be treated not as a static value but as a curve that varies during the course of the experiment. It factors in both flash cache’s endurance cost as well as the benefit of reduced backend workload.

\subsubsection{Cache Hit Rate}
Cache Hit Rate can be defined as the number of I/O requests served by the flash cache rather than the HDD backend.  The paper concludes that optimizing the cache hit rate cannot reliably reduce the pressure of the backend \cite{wong2024baleen, yan2020rlbelady}. Therefore, it will be included in the experiment only as a comparative metric against the other metrics.

\subsection{Analysis \& Reporting Plan}

The analysis will aggregate results across evaluation windows using medians and interquartile ranges (IQR), providing a summary of performance that reduces sensitivity to outliers. If resources allow, multiple random seeds will be used, and confidence intervals will be reported to strengthen the statistical reliability of the findings.

Comparisons will focus on baseline admission heuristics and the Baleen policies trained with ML-guided admission and coordinated prefetching\cite{eisenman2019flashield,yang2022cachesack}. The primary emphasis will be on Peak DT, since it reflects backend provisioning requirements, while cache hit rate will appear only as a diagnostic measure.

To explore parameter sensitivity, experiments will sweep the flash write rate constraint as well as the cache size. From these studies, figures are expected to show relationships such as Peak DT as a function of write rate, TCO as a function of write rate, and Peak DT under different cache sizes. These results will help characterize trade-offs between performance, endurance, and cost.

Finally, ablation experiments will disable prefetching to isolate the contribution of coordination. Figures from this stage will present direct comparisons between admission-only and admission-plus-prefetch configurations%\cite{hsieh2012cachingless, li2015ripq}.

\clearpage
%sample table 2AM

\begin{table}[H]
\centering
\caption{Summary of Parameter Effects on Peak DT and Hit Rate (from Figures 1–5)}
\label{tb:trend_summary}
\small
\begin{tabular}{p{3.5cm}p{4.5cm}p{4.5cm}}
\toprule
\textbf{Parameter} & \textbf{Impact on Peak DT} & \textbf{Impact on Hit Rate} \\
\midrule
DT-per-byte score ($\tau_{DT}$) & U-shaped curve; very low values cause high churn and high peak DT; mid-range improves DT & Peaks at mid-range (e.g., 0.01–0.02); too high underutilizes flash \\
PROTECTED Cap & Flat trend; little DT improvement across range & Slight decrease in hit rate as protection increases \\
ATTI & Flatter impact; slightly improved DT at lower thresholds & Hit rate reduces as ATTI increases; fewer reused blocks admitted \\
Prefetch & Improves DT stability by overlapping I/Os & No strong gain in hit rate observed \\
ML vs. Heuristic & Baleen achieves lower peak DT and higher hit rate overall & Baleen clearly outperforms DT-SLRU and RejectX in both metrics \\
\bottomrule
\end{tabular}
\end{table}




\clearpage

\begin{table}[H]
\centering
\caption{Observed Impact of Parameter Variation on Performance Metrics}
\label{tb:vertical_trend_table}
\small
\begin{tabular}{p{3.8cm}p{8.2cm}}
\toprule
\textbf{Parameter} & \textbf{Observed Trends} \\
\midrule

\multirow{2}{=}{DT-per-byte score ($\tau_{DT}$)} 
& \textbf{Peak DT}: U-shaped trend. Low $\tau_{DT}$ values allow noisy blocks, increasing DT. Mid-range values reduce DT effectively. High values lead to underutilization. \\
& \textbf{Hit Rate}: Best performance seen at $\tau_{DT}$ ≈ 0.01–0.02. Too small or too large values cause reduction in reuse effectiveness. \\
\midrule

\multirow{2}{=}{PROTECTED Cap} 
& \textbf{Peak DT}: Relatively flat across the full range. No significant improvement or degradation. \\
& \textbf{Hit Rate}: Slight downward slope as cap increases. More protected cache reduces flexibility for reuse. \\
\midrule

\multirow{2}{=}{ATTI} 
& \textbf{Peak DT}: Lower ATTI values offer slightly improved DT. High ATTI delays eviction unnecessarily. \\
& \textbf{Hit Rate}: Declines steadily with larger ATTI values, as blocks with marginal reuse are excluded. \\
\midrule

\multirow{2}{=}{Prefetching (enabled/disabled)} 
& \textbf{Peak DT}: With prefetching enabled, DT variability reduces, likely due to better I/O overlap. \\
& \textbf{Hit Rate}: Prefetching does not significantly improve hit rate on this trace. \\
\midrule

\multirow{2}{=}{Policy Type (ML vs. Baseline)} 
& \textbf{Peak DT}: Baleen's ML policy consistently shows lowest peak DT compared to DT-SLRU and RejectX. \\
& \textbf{Hit Rate}: Baleen also achieves higher hit rates due to dynamic threshold learning. \\
\bottomrule
\end{tabular}
\end{table}




\clearpage
\section{Member Contributions}

\subsection{Anna Gorislavets}

\begin{itemize}
    \item Responsible for the Planned Workloads \& Temporal Splits and Analysis \& Reporting Plan section.
    \item Edited language, formatting in LaTeX, as well as citations.
    \item Used Overleaf for collaboration.
    \item Ensured quality aligning with rubric requirements and additional research.
    \item Assisted in final proofreading.
\end{itemize}

\subsection{Bikash Shyangtang}

\begin{itemize}
    \item Help in different section of methodology Repository scope analysis and Baleen ML-informed Admission.
    \item Coordinated with team member for section design description and OPT imitation training.
    \item Use Overleaf for editing LaTeX and help in formatting report writing.
    \item Ensured quality by comparing content with source papers and validating technical clarity with peers.
    \item Supported in integration into LaTeX and helped organize group editing sessions.
\end{itemize}

\subsection{Hao Chen}

\begin{itemize}
    \item Responsible for the section Artifact and Environment Plan, Repository Scope Analysis, and Terminology mapping.
    \item Create and format LaTeX templates, create table.
    \item Overleaf for collaborative editing; Use Notion for project management and task tracking.
    \item Quality was ensured by reviewing the checklist from the grading rubric and proofreading the entire assignment with every group member present.
    \item Coordinated paper submission, used Notion to manage task progress and deadline, set up routine Zoom/Teams meetups.
\end{itemize}

\subsection{Maoting Li}

\begin{itemize}
    \item Responsible for defining the key metrics including Disk-head Time (DT), Peak DT, flash write rate, and estimated Total Cost of Ownership (TCO)
    \item Drafted 250+ words explaining these metrics and how they are measured in later experiments
    \item Tools Used: Overleaf
    \item Quality was ensured by aligning the written passage closely with the grading rubric and ensuring that the captions and diagrams are consistent with the requirements asked in the rubric
    \item Contributed to overall editing by reviewing group sections for consistency in writing style and formatting.
\end{itemize}

\subsection{Salinrat Thanathapsakun}

\begin{itemize}
    \item Responsible for Planned Policies \& Training section, covering baseline admission heuristic (RejectX) and Baleen’s ML-informed admission with prefetching.
    \item Drafted evaluation design description, summarized OPT-imitation training, and integrated artifact commands and configurations into the section.
    \item Used Overleaf for LaTeX writing/formatting and GitHub (Baleen-FAST24 artifact) for script referencing.
    \item Verified policy descriptions against the Baleen paper and artifact README, proofread for clarity and technical accuracy, and ensured rubric compliance.
    \item Coordinated feedback integration for Section 1.3, aligned terminology with other report parts, and managed version tracking in Overleaf.
\end{itemize}


\begin{comment}
\section{Citations and Bibliographies}

The use of \BibTeX\ for the preparation and formatting of one's
references is strongly recommended. Authors' names should be complete
--- use full first names (``Donald E. Knuth'') not initials
(``D. E. Knuth'') --- and the salient identifying features of a
reference should be included: title, year, volume, number, pages,
article DOI, etc.

The bibliography is included in your source document with these two
commands, placed just before the \verb|\end{document}| command:
\begin{verbatim}
  \bibliographystyle{ACM-Reference-Format}
  \bibliography{bibfile}
\end{verbatim}
where ``\verb|bibfile|'' is the name, without the ``\verb|.bib|''
suffix, of the \BibTeX\ file.

Citations and references are numbered by default. A small number of
ACM publications have citations and references formatted in the
``author year'' style; for these exceptions, please include this
command in the {\bfseries preamble} (before the command
``\verb|\begin{document}|'') of your \LaTeX\ source:
\begin{verbatim}
  \citestyle{acmauthoryear}
\end{verbatim}


  Some examples.  A paginated journal article \cite{Abril07}, an
  enumerated journal article \cite{Cohen07}, a reference to an entire
  issue \cite{JCohen96}, a monograph (whole book) \cite{Kosiur01}, a
  monograph/whole book in a series (see 2a in spec. document)
  \cite{Harel79}, a divisible-book such as an anthology or compilation
  \cite{Editor00} followed by the same example, however we only output
  the series if the volume number is given \cite{Editor00a} (so
  Editor00a's series should NOT be present since it has no vol. no.),
  a chapter in a divisible book \cite{Spector90}, a chapter in a
  divisible book in a series \cite{Douglass98}, a multi-volume work as
  book \cite{Knuth97}, a couple of articles in a proceedings (of a
  conference, symposium, workshop for example) (paginated proceedings
  article) \cite{Andler79, Hagerup1993}, a proceedings article with
  all possible elements \cite{Smith10}, an example of an enumerated
  proceedings article \cite{VanGundy07}, an informally published work
  \cite{Harel78}, a couple of preprints \cite{Bornmann2019,
    AnzarootPBM14}, a doctoral dissertation \cite{Clarkson85}, a
  master's thesis: \cite{anisi03}, an online document / world wide web
  resource \cite{Thornburg01, Ablamowicz07, Poker06}, a video game
  (Case 1) \cite{Obama08} and (Case 2) \cite{Novak03} and \cite{Lee05}
  and (Case 3) a patent \cite{JoeScientist001}, work accepted for
  publication \cite{rous08}, 'YYYYb'-test for prolific author
  \cite{SaeediMEJ10} and \cite{SaeediJETC10}. Other cites might
  contain 'duplicate' DOI and URLs (some SIAM articles)
  \cite{Kirschmer:2010:AEI:1958016.1958018}. Boris / Barbara Beeton:
  multi-volume works as books \cite{MR781536} and \cite{MR781537}. A
  presentation~\cite{Reiser2014}. An article under
  review~\cite{Baggett2025}. A
  couple of citations with DOIs:
  \cite{2004:ITE:1009386.1010128,Kirschmer:2010:AEI:1958016.1958018}. Online
  citations: \cite{TUGInstmem, Thornburg01, CTANacmart}.
  Artifacts: \cite{R} and \cite{UMassCitations}.


\end{comment}
%%
%% The next two lines define the bibliography style to be used, and
%% the bibliography file.
% \nocite{song2020lrb} % this will cite everything in *.bib file
%\citestyle{acmauthoryear}

\citestyle{acmnumeric}
\bibliographystyle{ACM-Reference-Format}
%\bibliographystyle{IEEEtran}
\clearpage
% \onecolumn make the document one column
\bibliography{ref}
%\bibliography{sample-base}

\clearpage

%%
%% If your work has an appendix, this is the place to put it.
% \appendix

% \section{Supplemental Material}

% \begin{figure}[ht!]
%   \centering
%   \includesvg[width=0.40\textwidth]{a1_diagrams/CSCI6806_storage_stack.svg}
%   \caption{Storage Architecture Diagram}
%   \label{fig:2}
% \end{figure}

\end{document}
\endinput
%%
%% End of file `sample-sigconf.tex'.
